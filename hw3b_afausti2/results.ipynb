{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gym\n",
    "import my_acrobot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dqn import DQN\n",
    "from dqn import Transition\n",
    "from dqn import ReplayMemory\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default tensor type to Double\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "# initialize env and net agents\n",
    "env = gym.make('MyAcrobot-v0')\n",
    "\n",
    "in_channels = env.observation_space.n\n",
    "out_channels = env.action_space.n\n",
    "batch_size = 64\n",
    "reward_decay = .99\n",
    "eps_start = 1.\n",
    "eps_end = .01\n",
    "target_update = 10\n",
    "device = \"cpu\"\n",
    "\n",
    "policy_net = DQN(in_channels, out_channels, batch_size, reward_decay, eps_start=1., eps_end=.01).to(device)\n",
    "target_net = DQN(in_channels, out_channels, batch_size, reward_decay, eps_start=1., eps_end=.01).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    transitions = memory.sample(batch_size)\n",
    "    # Transpose the batch (see http://stackoverflow.com/a/19343/3343043 for detailed explanation.)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.uint8)\n",
    "    non_final_next_states = torch.stack([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    next_state_values = torch.zeros(batch_size, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * reward_decay) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 5000\n",
    "max_time = 100\n",
    "all_cum_rewards = np.array(0)\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    state = torch.tensor(env.reset(), device=device)\n",
    "    episode_cum_reward = 0\n",
    "    for t in range(max_time):\n",
    "        # Select and perform an action\n",
    "        action = policy_net.select_action(state)\n",
    "        next_state, reward, done, info = env.step(action.item())\n",
    "        # state = torch.tensor(state, device=device)\n",
    "        # action = torch.tensor([action], device=device)\n",
    "        next_state = torch.tensor(next_state, device=device)\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        episode_cum_reward += reward\n",
    "        if done:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "\n",
    "    # Update the target network\n",
    "    if i_episode % target_update == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "    all_cum_rewards = np.append(all_cum_rewards, episode_cum_reward)\n",
    "    \n",
    "all_cum_rewards = all_cum_rewards[0:-1]\n",
    "plt.plot(range(num_episodes), all_cum_rewards, 'r')\n",
    "plt.ylabel('episode cumulative reward')\n",
    "plt.xlabel('episode number')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a delta of pi/4 the agent never finds any reward. I'm going to try to adjust batch size and torque magnitude next."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
