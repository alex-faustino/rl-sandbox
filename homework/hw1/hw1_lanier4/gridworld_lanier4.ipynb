{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Create the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dan Lanier AE598RL \"\"\"\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "class grid_env(gym.Env):\n",
    "    \n",
    "    def __init__(self, p=None, rows=5, cols=5):\n",
    "        if not (p is not None and isinstance(p, (np.ndarray, np.generic) ) and p.size == 2):\n",
    "            p = np.array([0,0])\n",
    "            \n",
    "        self.rows = np.cumsum(np.int_(np.ones(rows))) - 1\n",
    "        self.cols = np.cumsum(np.int_(np.ones(cols))) - 1\n",
    "        self.rewards_dict = {'A': {'p':[0, 1], 'reward': 10, 'new_p':[4, 1]} , \n",
    "                             'B': {'p':[0, 3], 'reward': 5, 'new_p':[4, 3]}}\n",
    "        self.p = self.set_p(p)\n",
    "        self.done = False\n",
    "        \n",
    "    def step(self, dp):\n",
    "        reward = self.get_reward_and_set_position(dp)\n",
    "        \n",
    "        return reward, self.get_p(), self.done, {}\n",
    "    \n",
    "    def get_reward_and_set_position(self, dp):\n",
    "        maybe_p = np.add(self.p, dp)\n",
    "        reward = 0\n",
    "        \n",
    "        if self.out_of_bounds(maybe_p):\n",
    "            reward = -1\n",
    "            \n",
    "        elif all(maybe_p == self.rewards_dict['A']['p']):\n",
    "            reward = self.rewards_dict['A']['reward']\n",
    "            self.p = self.set_p(self.rewards_dict['A']['new_p'])\n",
    "        elif all(maybe_p == self.rewards_dict['B']['p']):\n",
    "            reward = self.rewards_dict['B']['reward']\n",
    "            self.p = self.set_p(self.rewards_dict['B']['new_p'])\n",
    "        else:\n",
    "            self.p = self.set_p(maybe_p)\n",
    "            \n",
    "        return reward\n",
    "            \n",
    "    def out_of_bounds(self, p):\n",
    "        bdck = self.check_bounds(p)\n",
    "        if bdck['rows']['low'] or  bdck['rows']['high'] or bdck['cols']['low'] or bdck ['cols']['high']:\n",
    "            out_of_bounds = True\n",
    "        else:\n",
    "            out_of_bounds = False\n",
    "        return out_of_bounds\n",
    "    \n",
    "    def check_bounds(self, p):\n",
    "        return {'rows': {'low': p[0] < self.rows.min(), 'high': p[0] > self.rows.max()}, \\\n",
    "                       'cols': {'low': p[1] < self.cols.min(), 'high': p[1] > self.cols.max()}}\n",
    "        \n",
    "    def get_p(self):\n",
    "        return self.p\n",
    "    \n",
    "    def set_p(self, p):\n",
    "        bounds_check_dict = self.check_bounds(p)\n",
    "        if bounds_check_dict['rows']['low']:\n",
    "            p[0] = self.rows.min()\n",
    "        elif bounds_check_dict['rows']['high']:\n",
    "            p[0] = self.rows.max()\n",
    "        if bounds_check_dict['cols']['low']:\n",
    "            p[1] = self.cols.min()\n",
    "        elif bounds_check_dict['cols']['high']:\n",
    "            p[1] = self.cols.max()\n",
    "            \n",
    "        return p\n",
    "    \n",
    "def get_random_move():\n",
    "    return np.array([np.random.randint(0,3) -1, np.random.randint(0,3) -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The next cell is the chaos agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Initial Position: [0 0]\n",
      "\n",
      "number of landings \n",
      " [[21 12  6  8  1]\n",
      " [21 25 24 13  5]\n",
      " [33 35 30 40 24]\n",
      " [61 54 71 56 67]\n",
      " [51 90 88 91 73]]\n",
      "\n",
      "\n",
      "Rewards - Value_matrix\n",
      " [[ -8 120  -2  40   0]\n",
      " [ -5   0   0   0   0]\n",
      " [-10   0   0   0  -8]\n",
      " [-18   0   0   0 -25]\n",
      " [-25 -39 -28 -41 -43]]\n",
      "\n",
      "negative rewards -252 \n",
      "positive rewards 160\n"
     ]
    }
   ],
   "source": [
    "env = grid_env(np.array([0,0]))\n",
    "print('Environment Initial Position:',env.p)\n",
    "\n",
    "positives_reward_sum = 0\n",
    "neg_rewards_sum = 0\n",
    "negatives_limit = 10000\n",
    "crash_limit = 1000\n",
    "n_while = 0\n",
    "landed_matrix = np.int_(np.zeros([5,5]))\n",
    "Value_matrix = np.int_(np.zeros([5,5]))\n",
    "while np.abs(neg_rewards_sum) < negatives_limit and n_while < crash_limit:\n",
    "    n_while += 1\n",
    "    maybe_p = get_random_move()\n",
    "    reward, p, done, _ = env.step(maybe_p)\n",
    "    \n",
    "    if reward < 0:\n",
    "        neg_rewards_sum += reward\n",
    "        Value_matrix[p[0], p[1]] += reward\n",
    "        landed_matrix[p[0], p[1]] += 1\n",
    "    else:\n",
    "        positives_reward_sum += reward\n",
    "        if reward == 5:\n",
    "            Value_matrix[0, 3] += reward\n",
    "            landed_matrix[0, 3] += 1\n",
    "        elif reward == 10:\n",
    "            Value_matrix[0, 1] += reward\n",
    "            landed_matrix[0, 1] += 1\n",
    "        else:\n",
    "            landed_matrix[p[0], p[1]] += 1\n",
    "\n",
    "print('\\nnumber of landings \\n',landed_matrix)\n",
    "print('\\n')\n",
    "print('Rewards - Value_matrix\\n',Value_matrix)\n",
    "print('\\nnegative rewards',neg_rewards_sum,'\\npositive rewards',positives_reward_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
