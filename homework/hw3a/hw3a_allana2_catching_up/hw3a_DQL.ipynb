{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separation of Previous Code into Environment and Agent Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import gym\n",
    "import sys\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import matplotlib.ticker as plticker\n",
    "import Gridworld_Env, Q_Learning_Agent\n",
    "\n",
    "world = Gridworld_Env.gridworld()\n",
    "agent = Q_Learning_Agent.qLearning(world,'')#'render' with quotes to show environment\n",
    "agent.work()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Using PyTorch\n",
    "The neural network model uses array-style inputs and outputs, so I have to change my Q function from it's original form in Q_Learning_Agent to an arrayed form in Q_Learning_Agent_Arrayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import gym\n",
    "import sys\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import matplotlib.ticker as plticker\n",
    "import Gridworld_Env, Q_Learning_Agent_Arrayed\n",
    "\n",
    "world = Gridworld_Env.gridworld()\n",
    "agent = Q_Learning_Agent_Arrayed.qLearning(world,'')#'render' with quotes to show environment\n",
    "agent.work()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Used to PyTorch\n",
    "The below code seems to work, now making it into a class file. Code from https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "\n",
    "However, upon biasing the output deterministically, we see that the learning algorithm is not stable in its performance. However, the perfomance is stable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 10, 1, 100, 4\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)*10\n",
    "#y[0] = torch.tensor([0,10,0,5])\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, H+100, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H+100, H+50, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H+50, H, bias=True),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(2000):\n",
    "    y_pred = model(x)#prediction step is called forward pass\n",
    "    \n",
    "#    print(y_pred)\n",
    "    \n",
    "    loss = loss_fn(y_pred, y)#loss calculation for feedback\n",
    "    print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()#gradient of loss step is called backward pass\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(y)\n",
    "y2 = y\n",
    "y2[0] = torch.tensor([0,10,0,5])\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfering models between off-policy network and target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred\n",
    "model2 = model\n",
    "y_pred2 = model2(x)\n",
    "print(y_pred)\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Deep Q-Learning Agent in Gridworld Environment\n",
    "## Steps for implementation\n",
    "* Weights initialized \n",
    "### Looping\n",
    "* NN \"forward pass\" (prediction of Q function) is sent to Agent\n",
    "* Agent makes decision and observes reward. The reward is sent back to NN along with the currently used Q function\n",
    "* Send Current Q function estimate for the agent's exploiting policy action (regardless if agent performs action) and newly observed reward to NN class file\n",
    "* Agent reperforms \"forward pass\" (prediction of Q function) to facilitate the calculation of loss with respect to the received Q function estimate for agent's exploit action and the observed reward\n",
    "* Repeat but without weight initialization\n",
    "\n",
    "## Progress\n",
    "### Done\n",
    "* Weights already randomly initialized using above code\n",
    "### Need to Do\n",
    "* Forward pass sent to agent\n",
    " * Need to include NN in agent's __init__ to enable receiving forward pass output for actions related to agent's state\n",
    " * Need to include agent in NN's __init__ to receive state, reward and to receive Q function estimate (y_pred) from agent\n",
    "#### Progress Notes\n",
    "Example code, upon which my implementation is based, randomly initizlizes input and output to the network, but not necessarily the weights? From reviewing the tutorial, it seems that the weights are randomly initialized as part of the establishment of a model network. I'll operate on that assumption for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict\n",
      "tensor([0.8163])\n",
      "tensor([[0.8163]])\n",
      "predict\n",
      "tensor([0.6735])\n",
      "tensor([[0.6735]])\n",
      "update\n",
      "tensor([[0.6735],\n",
      "        [0.9184],\n",
      "        [0.2653],\n",
      "        [0.5714],\n",
      "        [0.4694],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.1020],\n",
      "        [1.0612],\n",
      "        [0.1837],\n",
      "        [0.1224],\n",
      "        [0.0612],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9388],\n",
      "        [0.7551],\n",
      "        [0.0612],\n",
      "        [0.6122],\n",
      "        [0.2653],\n",
      "        [1.0408],\n",
      "        [0.9592]])\n",
      "tensor([[0.6735],\n",
      "        [0.9184],\n",
      "        [0.2653],\n",
      "        [0.5714],\n",
      "        [0.4694],\n",
      "        [1.0000],\n",
      "        [0.0000],\n",
      "        [1.1020],\n",
      "        [1.0612],\n",
      "        [0.1837],\n",
      "        [0.1224],\n",
      "        [0.0612],\n",
      "        [0.0000],\n",
      "        [1.0000],\n",
      "        [0.9388],\n",
      "        [0.7551],\n",
      "        [0.0612],\n",
      "        [0.6122],\n",
      "        [0.2653],\n",
      "        [1.0408],\n",
      "        [0.9592]])\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1590256d1b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmy_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreluNetworkClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqLearningNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_nn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ_Learning_Agent_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_nn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_nn2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#'render' with quotes to show environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/floppsy/Desktop/598rl/homework/hw3a/hw3a_allana2_catching_up/Q_Learning_Agent_nn.py\u001b[0m in \u001b[0;36mwork\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m## train main neural network ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m              \u001b[0mtemporary_nn_main_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminibatch_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemporary_nn_main_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminibatch_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_q_function\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminibatch_log\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmy_gamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m## train target neural network (logic in class file to only update when appropriate) ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/floppsy/Desktop/598rl/homework/hw3a/hw3a_allana2_catching_up/reluNetworkClass.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, state, reward, previous_q_function, discount)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# necessary to unpack array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_q_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdiscount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#second term is target and first term is estimate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#  print(self.loss.item()) # to see training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/floppsy/anaconda3/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2332\u001b[0m     \"\"\"\n\u001b[1;32m   2333\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2334\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/floppsy/anaconda3/lib/python3.5/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/floppsy/anaconda3/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     26\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     27\u001b[0m           initial=_NoValue):\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import gym\n",
    "import sys\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "import matplotlib.ticker as plticker\n",
    "import Gridworld_Env_General, Q_Learning_Agent_nn\n",
    "import reluNetworkClass, reluNetworkClass2\n",
    "\n",
    "world = Gridworld_Env_General.gridworld()\n",
    "my_nn2 = reluNetworkClass2.qLearningNetwork(world)\n",
    "my_nn = reluNetworkClass.qLearningNetwork(world,my_nn2)\n",
    "agent = Q_Learning_Agent_nn.qLearning(world,my_nn,my_nn2,'')#'render' with quotes to show environment\n",
    "agent.work()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
