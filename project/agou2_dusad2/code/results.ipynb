{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "- https://github.com/hardmaru/WorldModelsExperiments\n",
    "- http://blog.otoro.net//2018/06/09/world-models-experiments/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import importlib\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import PIL\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mountain Car Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "ims = []\n",
    "for i in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    state, r, done, _ = env.step(action)\n",
    "    im = env.render(mode='rgb_array')\n",
    "    ims.append(im)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_ims = [Image.fromarray(i).resize((64, 64), Image.BILINEAR) for i in ims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_ims = [np.array(i) for i in resized_ims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resized_ims = np.array(resized_ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.distributions.distribution.Distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function normal:\n",
      "\n",
      "normal(...)\n",
      "    .. function:: normal(mean, std, out=None) -> Tensor\n",
      "    \n",
      "    Returns a tensor of random numbers drawn from separate normal distributions\n",
      "    whose mean and standard deviation are given.\n",
      "    \n",
      "    The :attr:`mean` is a tensor with the mean of\n",
      "    each output element's normal distribution\n",
      "    \n",
      "    The :attr:`std` is a tensor with the standard deviation of\n",
      "    each output element's normal distribution\n",
      "    \n",
      "    The shapes of :attr:`mean` and :attr:`std` don't need to match, but the\n",
      "    total number of elements in each tensor need to be the same.\n",
      "    \n",
      "    .. note:: When the shapes do not match, the shape of :attr:`mean`\n",
      "              is used as the shape for the returned output tensor\n",
      "    \n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "        out (Tensor, optional): the output tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\n",
      "        tensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n",
      "                  8.0505,   8.1408,   9.0563,  10.0566])\n",
      "    \n",
      "    .. function:: normal(mean=0.0, std, out=None) -> Tensor\n",
      "    \n",
      "    Similar to the function above, but the means are shared among all drawn\n",
      "    elements.\n",
      "    \n",
      "    Args:\n",
      "        mean (float, optional): the mean for all distributions\n",
      "        std (Tensor): the tensor of per-element standard deviations\n",
      "        out (Tensor, optional): the output tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=0.5, std=torch.arange(1., 6.))\n",
      "        tensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n",
      "    \n",
      "    .. function:: normal(mean, std=1.0, out=None) -> Tensor\n",
      "    \n",
      "    Similar to the function above, but the standard-deviations are shared among\n",
      "    all drawn elements.\n",
      "    \n",
      "    Args:\n",
      "        mean (Tensor): the tensor of per-element means\n",
      "        std (float, optional): the standard deviation for all distributions\n",
      "        out (Tensor, optional): the output tensor\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.normal(mean=torch.arange(1., 6.))\n",
      "        tensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, z_size=32, batch_size=1, learning_rate=0.0001, kl_tolerance=0.5, gpu=False):\n",
    "        self.z_size=z_size,\n",
    "        self.batch_size=batch_size, \n",
    "        self.learning_rate=learning_rate, \n",
    "        self.kl_tolerance=kl_tolerance\n",
    "        self.gpu = gpu\n",
    "        \n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.mu = nn.Linear(256*2*2, self.z_size)\n",
    "        self.logvar = nn.Linear(256*2*2, self.z_size)\n",
    "        self.sigma = torch.exp(self.logvar/2.0)\n",
    "        self.eps = torch.normal()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        \n",
    "        mu = self.mu(out)\n",
    "        sigma = \n",
    "        return out\n",
    "# h = tf.layers.conv2d(self.x, 32, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv1\")\n",
    "# h = tf.layers.conv2d(h, 64, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv2\")\n",
    "# h = tf.layers.conv2d(h, 128, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv3\")\n",
    "# h = tf.layers.conv2d(h, 256, 4, strides=2, activation=tf.nn.relu, name=\"enc_conv4\")\n",
    "# h = tf.reshape(h, [-1, 2*2*256])\n",
    "    \n",
    "# self.mu = tf.layers.dense(h, self.z_size, name=\"enc_fc_mu\")\n",
    "#       self.logvar = tf.layers.dense(h, self.z_size, name=\"enc_fc_log_var\")\n",
    "#       self.sigma = tf.exp(self.logvar / 2.0)\n",
    "#       self.epsilon = tf.random_normal([self.batch_size, self.z_size])\n",
    "#       self.z = self.mu + self.sigma * self.epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = VAE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))\n",
       "    (7): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = torch.from_numpy(resized_ims)\n",
    "var = var.reshape((1000, 3, 64, 64)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.forward(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 32, 31, 31])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 31, 31]           1,568\n",
      "              ReLU-2           [-1, 32, 31, 31]               0\n",
      "            Conv2d-3           [-1, 64, 14, 14]          32,832\n",
      "              ReLU-4           [-1, 64, 14, 14]               0\n",
      "            Conv2d-5            [-1, 128, 6, 6]         131,200\n",
      "              ReLU-6            [-1, 128, 6, 6]               0\n",
      "            Conv2d-7            [-1, 256, 2, 2]         524,544\n",
      "              ReLU-8            [-1, 256, 2, 2]               0\n",
      "================================================================\n",
      "Total params: 690,144\n",
      "Trainable params: 690,144\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.75\n",
      "Params size (MB): 2.63\n",
      "Estimated Total Size (MB): 3.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
