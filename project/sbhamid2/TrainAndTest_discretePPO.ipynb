{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cases 1, 2, 3 and 4\n",
    "\n",
    "### using observation vector as input and discrete velocity action as output\n",
    "#### This notebook allows you to train PPO for various parameters and later test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import ppo_twonet_discrete as ppo\n",
    "import gym \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from urbanworld.urbanworld import UrbanWorldEnv\n",
    "\n",
    "env = gym.make('MyUrbanWorld-v1')\n",
    "env.env.version = 'easy'\n",
    "\n",
    "### this will plot the 3D plot of the urban environment\n",
    "env.env.plot = False\n",
    "\n",
    "### Modify the height vector to change the cases from open-sky conditions to urban area conditions\n",
    "env.env.HEIGHT = [[80]*7]*7\n",
    "\n",
    "### Observation/Position vector\n",
    "env.env.mode = 'pos' ##'obs' ## \n",
    "a_seed = 0\n",
    "env.seed(a_seed)\n",
    "\n",
    "set_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### urban v1 version\n",
    "set_params.update({'clip': 0.2, 'max_grad': 0.6, 'ppo_epoch': 30, 'mem_size': 1000, 'batch_size': 32, \\\n",
    "                   'gamma': 0.9, 'no_eps': 2000, 'eps_len': 1000, 'env': env, 'lr': 1e-3})\n",
    "urban_v1 = ppo.Agent(env)\n",
    "rewards_v1, Lclip_v1, Lvalue_v1 = urban_v1.train_model(set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### urban v5 version -> Changing memory size\n",
    "set_params.update({'clip': 0.2, 'max_grad': 0.5, 'ppo_epoch': 50, 'mem_size': 600, 'batch_size': 32, \\\n",
    "                   'gamma': 0.9, 'no_eps': 1500, 'eps_len': 1000, 'env': env, 'lr': 1e-4})\n",
    "urban_v5 = ppo.Agent(env)\n",
    "rewards_v5, Lclip_v5, Lvalue_v5 = urban_v5.train_model(set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### urban v3 version-> Changing learning rate\n",
    "set_params.update({'clip': 0.2, 'max_grad': 0.5, 'ppo_epoch': 30, 'mem_size': 1000, 'batch_size': 32, \\\n",
    "                   'gamma': 0.9, 'no_eps': 1500, 'eps_len': 1000, 'env': env, 'lr': 1e-2})\n",
    "urban_v3 = ppo.Agent(env)\n",
    "rewards_v3, Lclip_v3, Lvalue_v3 = urban_v3.train_model(set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### urban v4 version -> Changing batch size\n",
    "set_params.update({'clip': 0.2, 'max_grad': 0.5, 'ppo_epoch': 10, 'mem_size': 1000, 'batch_size': 64, \\\n",
    "                   'gamma': 0.9, 'no_eps': 1500, 'eps_len': 1000, 'env': env, 'lr': 1e-4})\n",
    "urban_v4 = ppo.Agent(env)\n",
    "rewards_v4, Lclip_v4, Lvalue_v4 = urban_v4.train_model(set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### urban v2 version -> Changing episode length\n",
    "set_params.update({'clip': 0.2, 'max_grad': 0.5, 'ppo_epoch': 10, 'mem_size': 1000, 'batch_size': 32, \\\n",
    "                   'gamma': 0.9, 'no_eps': 1500, 'eps_len': 1500, 'env': env, 'lr': 1e-4})\n",
    "urban_v2 = ppo.Agent(env)\n",
    "rewards_v2, Lclip_v2, Lvalue_v2 = urban_v2.train_model(set_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.transpose(rewards_v1)[0], np.transpose(rewards_v1)[1]/(urban_v1.eps_len), 'b.')\n",
    "plt.plot(np.transpose(rewards_v1)[0], np.transpose(rewards_v1)[1]/(urban_v1.eps_len), 'b', label='default')\n",
    "\n",
    "plt.plot(np.transpose(rewards_v2)[0], np.transpose(rewards_v2)[1]/(urban_v2.eps_len), 'r.')\n",
    "plt.plot(np.transpose(rewards_v2)[0], np.transpose(rewards_v2)[1]/(urban_v2.eps_len), 'r', label='mem_size')#\n",
    "\n",
    "plt.plot(np.transpose(rewards_v3)[0], np.transpose(rewards_v3)[1]/(urban_v3.eps_len), 'g.')\n",
    "plt.plot(np.transpose(rewards_v3)[0], np.transpose(rewards_v3)[1]/(urban_v3.eps_len), 'g', label='lr')\n",
    "\n",
    "plt.plot(np.transpose(rewards_v4)[0], np.transpose(rewards_v4)[1]/(urban_v4.eps_len), 'k.')\n",
    "plt.plot(np.transpose(rewards_v4)[0], np.transpose(rewards_v4)[1]/(urban_v4.eps_len), 'k', label='batch_size')\n",
    "\n",
    "plt.plot(np.transpose(rewards_v5)[0], np.transpose(rewards_v5)[1]/(urban_v5.eps_len), 'm.')\n",
    "plt.plot(np.transpose(rewards_v5)[0], np.transpose(rewards_v5)[1]/(urban_v5.eps_len), 'm', label='eps_len')\n",
    "\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Reward')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is for testing the model!\n",
    "eps_len = 400\n",
    "agent = urban_v3\n",
    "record_pos, record_action, rewards = agent.test_model(eps_len)\n",
    "print('Rewards attained: ', rewards)\n",
    "plt.figure()\n",
    "get_angle = np.arctan2(np.transpose(record_pos)[1], np.transpose(record_pos)[0])* 180 / np.pi\n",
    "plt.subplot(211)\n",
    "plt.plot(np.arange(eps_len), get_angle, 'b')\n",
    "plt.plot(np.arange(eps_len), get_angle, 'b.')\n",
    "plt.subplot(212)\n",
    "plt.plot(np.arange(eps_len), np.transpose(record_pos)[2], 'b')\n",
    "plt.plot(np.arange(eps_len), np.transpose(record_pos)[2], 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
